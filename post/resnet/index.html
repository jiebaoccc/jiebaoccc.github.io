<!DOCTYPE html>
<html lang="en-us" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content="网络结构图 18 至 34 layers 网络结构图 50 至 152 层网络结构图 具体代码实现 # model.py import torch import torch.nn as nn # 首先定义基本的块结构，通过不同的参数传递实现不同大小配置的块 # 此处定义的块结构是针对resnet18和resnet34这两种结构的，expansion参数表述主分支结构上卷积通道数的变化 # 在18和34两种结构中，每一个基础块结构中，主分支上的通道数事不发生变化的，故expansion=1 class BasicBlock(nn.Module): expansion = 1 def __init__(self,in_channel,out_channel,stride=1,downsample=None,**kwargs): super(BasicBlock,self).__init__() self.conv1 = nn.Conv2d(in_channels=in_channel,out_channels=out_channel, kernel_size=3,stride=stride,padding=1,bias=False) self.bn1 = nn.BatchNorm2d(out_channel) self.relu = nn.ReLU() self.conv2 = nn.Conv2d(in_channels=out_channel,out_channels=out_channel, kernel_size=3,stride=1,padding=1,bias=False) self.bn2 = nn.BatchNorm2d(out_channel) self.downsample = downsample def forward(self,x): identity = x if self.downsample is not None: identity = self.downsample(x) out = self.conv1(x) out = self.">
<title>ResNet</title>

<link rel='canonical' href='https://jiebaoccc.github.io/post/resnet/'>

<link rel="stylesheet" href="/scss/style.min.0304c6baf04e01a8fe70693791cb744d56a3578a3120a8796cefc66825aa39c7.css"><meta property='og:title' content="ResNet">
<meta property='og:description' content="网络结构图 18 至 34 layers 网络结构图 50 至 152 层网络结构图 具体代码实现 # model.py import torch import torch.nn as nn # 首先定义基本的块结构，通过不同的参数传递实现不同大小配置的块 # 此处定义的块结构是针对resnet18和resnet34这两种结构的，expansion参数表述主分支结构上卷积通道数的变化 # 在18和34两种结构中，每一个基础块结构中，主分支上的通道数事不发生变化的，故expansion=1 class BasicBlock(nn.Module): expansion = 1 def __init__(self,in_channel,out_channel,stride=1,downsample=None,**kwargs): super(BasicBlock,self).__init__() self.conv1 = nn.Conv2d(in_channels=in_channel,out_channels=out_channel, kernel_size=3,stride=stride,padding=1,bias=False) self.bn1 = nn.BatchNorm2d(out_channel) self.relu = nn.ReLU() self.conv2 = nn.Conv2d(in_channels=out_channel,out_channels=out_channel, kernel_size=3,stride=1,padding=1,bias=False) self.bn2 = nn.BatchNorm2d(out_channel) self.downsample = downsample def forward(self,x): identity = x if self.downsample is not None: identity = self.downsample(x) out = self.conv1(x) out = self.">
<meta property='og:url' content='https://jiebaoccc.github.io/post/resnet/'>
<meta property='og:site_name' content='Carp&#39;s blog'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:published_time' content='2024-10-03T00:02:36&#43;08:00'/><meta property='article:modified_time' content='2024-10-03T00:02:36&#43;08:00'/>
<meta name="twitter:title" content="ResNet">
<meta name="twitter:description" content="网络结构图 18 至 34 layers 网络结构图 50 至 152 层网络结构图 具体代码实现 # model.py import torch import torch.nn as nn # 首先定义基本的块结构，通过不同的参数传递实现不同大小配置的块 # 此处定义的块结构是针对resnet18和resnet34这两种结构的，expansion参数表述主分支结构上卷积通道数的变化 # 在18和34两种结构中，每一个基础块结构中，主分支上的通道数事不发生变化的，故expansion=1 class BasicBlock(nn.Module): expansion = 1 def __init__(self,in_channel,out_channel,stride=1,downsample=None,**kwargs): super(BasicBlock,self).__init__() self.conv1 = nn.Conv2d(in_channels=in_channel,out_channels=out_channel, kernel_size=3,stride=stride,padding=1,bias=False) self.bn1 = nn.BatchNorm2d(out_channel) self.relu = nn.ReLU() self.conv2 = nn.Conv2d(in_channels=out_channel,out_channels=out_channel, kernel_size=3,stride=1,padding=1,bias=False) self.bn2 = nn.BatchNorm2d(out_channel) self.downsample = downsample def forward(self,x): identity = x if self.downsample is not None: identity = self.downsample(x) out = self.conv1(x) out = self.">
  


    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column compact"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="Toggle Menu">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu8602028200308506927.png" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">Carp&#39;s blog</a></h1>
            <h2 class="site-description"></h2>
        </div>
    </header><ol class="menu" id="main-menu">
        
        
        <li class="menu-bottom-section">
            <ol class="menu">

                
                    <li id="dark-mode-toggle">
                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <span>Dark Mode</span>
                    </li>
                
            </ol>
        </li>
    </ol>
</aside>

    

            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/post/resnet/">ResNet</a>
        </h2>
    
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Oct 03, 2024</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    6 minute read
                </time>
            </div>
        
    </footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <p><strong>网络结构图</strong></p>
<p><img src="/ResNet_img/1.png"
	
	
	
	loading="lazy"
	
		alt="1"
	
	
></p>
<p><strong>18 至 34 layers 网络结构图</strong></p>
<p><img src="/ResNet_img/2.png"
	
	
	
	loading="lazy"
	
		alt="2"
	
	
></p>
<p><strong>50 至 152 层网络结构图</strong></p>
<p><img src="/ResNet_img/3.png"
	
	
	
	loading="lazy"
	
		alt="3"
	
	
></p>
<p><img src="/ResNet_img/4.png"
	
	
	
	loading="lazy"
	
		alt="4"
	
	
></p>
<p><strong>具体代码实现</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># model.py</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 首先定义基本的块结构，通过不同的参数传递实现不同大小配置的块</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 此处定义的块结构是针对resnet18和resnet34这两种结构的，expansion参数表述主分支结构上卷积通道数的变化</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 在18和34两种结构中，每一个基础块结构中，主分支上的通道数事不发生变化的，故expansion=1</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">BasicBlock</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    expansion <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self,in_channel,out_channel,stride<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,downsample<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>,<span style="color:#f92672">**</span>kwargs):
</span></span><span style="display:flex;"><span>        super(BasicBlock,self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>conv1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(in_channels<span style="color:#f92672">=</span>in_channel,out_channels<span style="color:#f92672">=</span>out_channel,
</span></span><span style="display:flex;"><span>                               kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>,stride<span style="color:#f92672">=</span>stride,padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>bn1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>BatchNorm2d(out_channel)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>relu <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>ReLU()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>conv2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(in_channels<span style="color:#f92672">=</span>out_channel,out_channels<span style="color:#f92672">=</span>out_channel,
</span></span><span style="display:flex;"><span>                               kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>,stride<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>bn2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>BatchNorm2d(out_channel)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>downsample <span style="color:#f92672">=</span> downsample
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self,x):
</span></span><span style="display:flex;"><span>        identity <span style="color:#f92672">=</span> x
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>downsample <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>            identity <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>downsample(x)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv1(x)
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>bn1(out)
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>relu(out)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv2(out)
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>bn2(out)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">+=</span> identity
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>relu(out)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> out
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Bottleneck</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    expansion <span style="color:#f92672">=</span> <span style="color:#ae81ff">4</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self,in_channel,out_channel,stride<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,downsample<span style="color:#f92672">=</span><span style="color:#66d9ef">None</span>,groups<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,width_per_group<span style="color:#f92672">=</span><span style="color:#ae81ff">64</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># groups表示组卷积的组数</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># width_per_group 是在 ResNeXt 中引入的一个参数，表示每个组卷积核的个数</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        super(Bottleneck,self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        width <span style="color:#f92672">=</span> int(out_channel <span style="color:#f92672">*</span> (width_per_group <span style="color:#f92672">/</span> <span style="color:#ae81ff">64.</span>)) <span style="color:#f92672">*</span> groups
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>conv1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(in_channels<span style="color:#f92672">=</span>in_channel,out_channels<span style="color:#f92672">=</span>width,
</span></span><span style="display:flex;"><span>                               kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,stride<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>bn1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>BatchNorm2d(width)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>conv2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(in_channels<span style="color:#f92672">=</span>width,out_channels<span style="color:#f92672">=</span>width,groups<span style="color:#f92672">=</span>groups,
</span></span><span style="display:flex;"><span>                               kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>,stride<span style="color:#f92672">=</span>stride,bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>bn2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>BatchNorm2d(width)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>conv3 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(in_channel<span style="color:#f92672">=</span>width,out_channels<span style="color:#f92672">=</span>out_channel <span style="color:#f92672">*</span> self<span style="color:#f92672">.</span>expansion,
</span></span><span style="display:flex;"><span>                               kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,stride<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>bn3 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>BatchNorm2d(out_channel <span style="color:#f92672">*</span> self<span style="color:#f92672">.</span>expansion)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>relu <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>ReLU(inplace <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>downsample <span style="color:#f92672">=</span> downsample
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self,x):
</span></span><span style="display:flex;"><span>        identity <span style="color:#f92672">=</span> x
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>downsample <span style="color:#f92672">is</span> <span style="color:#f92672">not</span> <span style="color:#66d9ef">None</span>:
</span></span><span style="display:flex;"><span>            identity <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>downsample(x)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv1(x)
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>bn1(out)
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>relu(out)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv2(out)
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>bn2(out)
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>relu(out)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv3(out)
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>bn3(out)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">+=</span> identity
</span></span><span style="display:flex;"><span>        out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>relu(out)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> out
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">ResNet</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self,
</span></span><span style="display:flex;"><span>                 block, <span style="color:#75715e"># 表示网络模型，如果为18或34层，则输入BasicBlock</span>
</span></span><span style="display:flex;"><span>                 block_num,
</span></span><span style="display:flex;"><span>                 num_classes <span style="color:#f92672">=</span> <span style="color:#ae81ff">1000</span>,
</span></span><span style="display:flex;"><span>                 include_top <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>                 groups<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
</span></span><span style="display:flex;"><span>                 width_per_group<span style="color:#f92672">=</span><span style="color:#ae81ff">64</span>):
</span></span><span style="display:flex;"><span>        super(ResNet,self)<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>include_top <span style="color:#f92672">=</span> include_top
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>in_channel <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>groups <span style="color:#f92672">=</span> groups
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>width_per_group <span style="color:#f92672">=</span> width_per_group
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>conv1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Conv2d(<span style="color:#ae81ff">3</span>,self<span style="color:#f92672">.</span>in_channel,kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">7</span>,stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>                               padding<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>,bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>bn1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>BatchNorm2d(self<span style="color:#f92672">.</span>in_channel)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>relu <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>ReLU(inplace<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>maxpool <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>MaxPool2d(kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>,stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,padding<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>layer1 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_make_layer(block,<span style="color:#ae81ff">64</span>,block_num[<span style="color:#ae81ff">0</span>])
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>layer2 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_make_layer(block,<span style="color:#ae81ff">128</span>,block_num[<span style="color:#ae81ff">1</span>],stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>layer3 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_make_layer(block,<span style="color:#ae81ff">256</span>,block_num[<span style="color:#ae81ff">2</span>],stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>layer4 <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>_make_layer(block,<span style="color:#ae81ff">512</span>,block_num[<span style="color:#ae81ff">3</span>],stride<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>include_top:
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>avgpool <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>AdaptiveAvgPool2d((<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>))
</span></span><span style="display:flex;"><span>            self<span style="color:#f92672">.</span>fc <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">512</span> <span style="color:#f92672">*</span> block<span style="color:#f92672">.</span>expansion,num_classes)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> m <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>modules():
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> isinstance(m,nn<span style="color:#f92672">.</span>Conv2d):
</span></span><span style="display:flex;"><span>                nn<span style="color:#f92672">.</span>init<span style="color:#f92672">.</span>kaiming_normal_(m<span style="color:#f92672">.</span>weight,mode<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;fan_out&#39;</span>,nonlinearity<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;relu&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">_make_layer</span>(self,block,channel,block_num,stride<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>        downsample <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> stride <span style="color:#f92672">!=</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">or</span> self<span style="color:#f92672">.</span>in_channel <span style="color:#f92672">!=</span> channel <span style="color:#f92672">*</span> block<span style="color:#f92672">.</span>expansion:
</span></span><span style="display:flex;"><span>            downsample <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>                nn<span style="color:#f92672">.</span>Conv2d(self<span style="color:#f92672">.</span>in_channel,channel<span style="color:#f92672">*</span>block<span style="color:#f92672">.</span>expansion,kernel_size<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,stride<span style="color:#f92672">=</span>stride,bias<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>),
</span></span><span style="display:flex;"><span>                nn<span style="color:#f92672">.</span>BatchNorm2d(channel <span style="color:#f92672">*</span> block<span style="color:#f92672">.</span>expansion))
</span></span><span style="display:flex;"><span>        layers <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>        layers<span style="color:#f92672">.</span>append(block(self<span style="color:#f92672">.</span>in_channel,
</span></span><span style="display:flex;"><span>                            channel,
</span></span><span style="display:flex;"><span>                            downsample <span style="color:#f92672">=</span> downsample,
</span></span><span style="display:flex;"><span>                            stride <span style="color:#f92672">=</span> stride,
</span></span><span style="display:flex;"><span>                            groups <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>groups,
</span></span><span style="display:flex;"><span>                            width_per_groups <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>width_per_group ))
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>in_channel <span style="color:#f92672">=</span> channel <span style="color:#f92672">*</span> block<span style="color:#f92672">.</span>expansion
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1</span>,block_num):
</span></span><span style="display:flex;"><span>            layers<span style="color:#f92672">.</span>append(block(self<span style="color:#f92672">.</span>in_channel,
</span></span><span style="display:flex;"><span>                                channel,
</span></span><span style="display:flex;"><span>                                groups <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>groups,
</span></span><span style="display:flex;"><span>                                width_per_groups <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>width_per_group))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> nn<span style="color:#f92672">.</span>Sequential(<span style="color:#f92672">*</span>layers)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self,x):
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>conv1(x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>bn1(x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>relu(x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>maxpool(x)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>layer1(x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>layer2(x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>layer3(x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>layer4(x)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> self<span style="color:#f92672">.</span>include_top:
</span></span><span style="display:flex;"><span>            x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>avgpool(x)
</span></span><span style="display:flex;"><span>            x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>flatten(x,<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>fc(x)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">resnet34</span>(num_classes<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>,include_top<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> ResNet(BasicBlock,[<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">4</span>,<span style="color:#ae81ff">6</span>,<span style="color:#ae81ff">3</span>],num_classes<span style="color:#f92672">=</span>num_classes,include_top<span style="color:#f92672">=</span>include_top)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">resnet50</span>(num_classes<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>,include_top<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> ResNet(Bottleneck,[<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">4</span>,<span style="color:#ae81ff">6</span>,<span style="color:#ae81ff">3</span>],num_classes<span style="color:#f92672">=</span>num_classes,include_top<span style="color:#f92672">=</span>include_top)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">resnet101</span>(num_classes<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>,include_top<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> ResNet(Bottleneck,[<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">4</span>,<span style="color:#ae81ff">23</span>,<span style="color:#ae81ff">3</span>],num_classes<span style="color:#f92672">=</span>num_classes,include_top<span style="color:#f92672">=</span>include_top)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">resnext50_32x4d</span>(num_classes<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>,include_top<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>):
</span></span><span style="display:flex;"><span>    groups<span style="color:#f92672">=</span><span style="color:#ae81ff">32</span>
</span></span><span style="display:flex;"><span>    width_per_group <span style="color:#f92672">=</span> <span style="color:#ae81ff">4</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> ResNet(Bottleneck,[<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">4</span>,<span style="color:#ae81ff">6</span>,<span style="color:#ae81ff">3</span>],
</span></span><span style="display:flex;"><span>                  num_classes<span style="color:#f92672">=</span>num_classes,
</span></span><span style="display:flex;"><span>                  include_top <span style="color:#f92672">=</span> include_top,
</span></span><span style="display:flex;"><span>                  groups<span style="color:#f92672">=</span>groups,
</span></span><span style="display:flex;"><span>                  width_per_group<span style="color:#f92672">=</span>width_per_group)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">resnext101_32x8d</span>(num_classes<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>,include_top<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>):
</span></span><span style="display:flex;"><span>    groups <span style="color:#f92672">=</span> <span style="color:#ae81ff">32</span>
</span></span><span style="display:flex;"><span>    width_per_group <span style="color:#f92672">=</span> <span style="color:#ae81ff">8</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> ResNet(Bottleneck,[<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">4</span>,<span style="color:#ae81ff">23</span>,<span style="color:#ae81ff">3</span>],
</span></span><span style="display:flex;"><span>                  num_classes<span style="color:#f92672">=</span>num_classes,
</span></span><span style="display:flex;"><span>                  include_top<span style="color:#f92672">=</span>include_top,
</span></span><span style="display:flex;"><span>                  groups<span style="color:#f92672">=</span>groups,
</span></span><span style="display:flex;"><span>                  width_per_group<span style="color:#f92672">=</span>width_per_group)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># train.py</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os   <span style="color:#75715e"># 导入系统操作库</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> sys  <span style="color:#75715e"># 文件操作库</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> json <span style="color:#75715e"># 用于保存和加载JSON格式的文件</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.optim <span style="color:#66d9ef">as</span> optim <span style="color:#75715e"># 提供优化算法</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torchvision.datasets
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torchvision <span style="color:#f92672">import</span> transforms, datasets
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> tqdm <span style="color:#f92672">import</span> tqdm   <span style="color:#75715e"># 进度条工具，便于可视化训练和验证的进度</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> model <span style="color:#f92672">import</span> resnet34  <span style="color:#75715e"># 导入ResNet34模型结构</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">main</span>():
</span></span><span style="display:flex;"><span>    device <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>device(<span style="color:#e6db74">&#34;cuda:0&#34;</span> <span style="color:#66d9ef">if</span> torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>is_available() <span style="color:#66d9ef">else</span> <span style="color:#e6db74">&#34;cpu&#34;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;using </span><span style="color:#e6db74">{}</span><span style="color:#e6db74"> device.&#34;</span><span style="color:#f92672">.</span>format(device))
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 检测是否能使用GPU</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 此处transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])中使用的是ImageNet数据集上图像RGB三通道的均值和方差</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 此处定义的是train和val阶段分别使用的数据处理方法</span>
</span></span><span style="display:flex;"><span>    data_transform <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;train&#34;</span>: transforms<span style="color:#f92672">.</span>Compose([transforms<span style="color:#f92672">.</span>RandomResizedCrop(<span style="color:#ae81ff">224</span>), <span style="color:#75715e"># 随机裁剪</span>
</span></span><span style="display:flex;"><span>                                     transforms<span style="color:#f92672">.</span>RandomHorizontalFlip(), <span style="color:#75715e"># 随机水平翻转</span>
</span></span><span style="display:flex;"><span>                                     transforms<span style="color:#f92672">.</span>ToTensor(),
</span></span><span style="display:flex;"><span>                                     transforms<span style="color:#f92672">.</span>Normalize([<span style="color:#ae81ff">0.485</span>, <span style="color:#ae81ff">0.456</span>, <span style="color:#ae81ff">0.456</span>], [<span style="color:#ae81ff">0.229</span>, <span style="color:#ae81ff">0.224</span>, <span style="color:#ae81ff">0.225</span>])]),  <span style="color:#75715e"># 归一化</span>
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;val&#34;</span>: transforms<span style="color:#f92672">.</span>Compose([transforms<span style="color:#f92672">.</span>Resize(<span style="color:#ae81ff">256</span>),
</span></span><span style="display:flex;"><span>                                   transforms<span style="color:#f92672">.</span>CenterCrop(<span style="color:#ae81ff">224</span>),
</span></span><span style="display:flex;"><span>                                   transforms<span style="color:#f92672">.</span>ToTensor(),
</span></span><span style="display:flex;"><span>                                   transforms<span style="color:#f92672">.</span>Normalize([<span style="color:#ae81ff">0.485</span>, <span style="color:#ae81ff">0.456</span>, <span style="color:#ae81ff">0.406</span>], [<span style="color:#ae81ff">0.229</span>, <span style="color:#ae81ff">0.224</span>, <span style="color:#ae81ff">0.225</span>])])}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    data_root <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;./data&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">assert</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>exists(data_root), <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{}</span><span style="color:#e6db74"> path does not exists.&#34;</span><span style="color:#f92672">.</span>format(data_root)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 当 assert 语句后的表达式值为真时，程序继续执行；反之，程序停止执行，并报 AssertionError 错误。</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># assert等效于if</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    train_dataset <span style="color:#f92672">=</span> torchvision<span style="color:#f92672">.</span>datasets<span style="color:#f92672">.</span>CIFAR10(
</span></span><span style="display:flex;"><span>        root <span style="color:#f92672">=</span> data_root,
</span></span><span style="display:flex;"><span>        train<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>        transform<span style="color:#f92672">=</span>data_transform[<span style="color:#e6db74">&#39;train&#39;</span>],
</span></span><span style="display:flex;"><span>        download<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    train_num <span style="color:#f92672">=</span> len(train_dataset)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 创建class_indices.json ， 以便读取数据集中各类别的编号</span>
</span></span><span style="display:flex;"><span>    flower_list <span style="color:#f92672">=</span> train_dataset<span style="color:#f92672">.</span>class_to_idx    <span style="color:#75715e"># 获取类别到索引的映射并</span>
</span></span><span style="display:flex;"><span>    cla_dict <span style="color:#f92672">=</span> dict((val, key) <span style="color:#66d9ef">for</span> key, val <span style="color:#f92672">in</span> flower_list<span style="color:#f92672">.</span>items()) <span style="color:#75715e"># 反转 “类别到索引” 成 “索引到类别” 的映射</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># write dict into json file</span>
</span></span><span style="display:flex;"><span>    json_str <span style="color:#f92672">=</span> json<span style="color:#f92672">.</span>dumps(cla_dict, indent<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>)   <span style="color:#75715e"># 将字典cla_dict转换成JSON格式的字符串，indent=4用于指定缩进格式，</span>
</span></span><span style="display:flex;"><span>                                                <span style="color:#75715e"># 使得生成的JSON文件更易读</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#39;class_indices.json&#39;</span>, <span style="color:#e6db74">&#39;w&#39;</span>) <span style="color:#66d9ef">as</span> json_file:  <span style="color:#75715e"># 将JSON格式的字符串写入 class_indices.json</span>
</span></span><span style="display:flex;"><span>        json_file<span style="color:#f92672">.</span>write(json_str)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">16</span> <span style="color:#75715e"># 定义批量为16</span>
</span></span><span style="display:flex;"><span>    nw <span style="color:#f92672">=</span> min([os<span style="color:#f92672">.</span>cpu_count(), batch_size <span style="color:#66d9ef">if</span> batch_size <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">1</span> <span style="color:#66d9ef">else</span> <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">8</span>])  <span style="color:#75715e"># num of workes 设置worker数为CPU核数与批量大小的最小值，</span>
</span></span><span style="display:flex;"><span>                                                                        <span style="color:#75715e"># 最多为8个worker</span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#39;Using </span><span style="color:#e6db74">{}</span><span style="color:#e6db74"> dataloader workers every process&#39;</span><span style="color:#f92672">.</span>format(nw))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    train_loader <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader(train_dataset,
</span></span><span style="display:flex;"><span>                                               batch_size<span style="color:#f92672">=</span>batch_size,
</span></span><span style="display:flex;"><span>                                               shuffle<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,    <span style="color:#75715e"># 是否打乱</span>
</span></span><span style="display:flex;"><span>                                               num_workers<span style="color:#f92672">=</span>nw)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 读取数据集</span>
</span></span><span style="display:flex;"><span>    validate_dataset <span style="color:#f92672">=</span> torchvision<span style="color:#f92672">.</span>datasets<span style="color:#f92672">.</span>CIFAR10(
</span></span><span style="display:flex;"><span>        root<span style="color:#f92672">=</span>data_root,
</span></span><span style="display:flex;"><span>        train<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>        transform<span style="color:#f92672">=</span>data_transform[<span style="color:#e6db74">&#39;val&#39;</span>],
</span></span><span style="display:flex;"><span>        download<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span><span style="color:#75715e"># 加载数据集</span>
</span></span><span style="display:flex;"><span>    val_num <span style="color:#f92672">=</span> len(validate_dataset)
</span></span><span style="display:flex;"><span>    validate_loader <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader(validate_dataset,
</span></span><span style="display:flex;"><span>                                                  batch_size<span style="color:#f92672">=</span>batch_size,
</span></span><span style="display:flex;"><span>                                                  shuffle<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>                                                  num_workers<span style="color:#f92672">=</span>nw)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;using </span><span style="color:#e6db74">{}</span><span style="color:#e6db74"> images for training, </span><span style="color:#e6db74">{}</span><span style="color:#e6db74"> images for validation.&#34;</span><span style="color:#f92672">.</span>format(train_num,
</span></span><span style="display:flex;"><span>                                                                           val_num))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    net <span style="color:#f92672">=</span> resnet34()  <span style="color:#75715e"># 模型实例化</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># load pretrain weights</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># download url: https://download.pytorch.org/models/resnet34-333f7ec4.pth</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    model_weight_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;./resnet34-pre.pth&#34;</span>  <span style="color:#75715e"># load模型的权重文件，需提前下载</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">assert</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>exists(model_weight_path), <span style="color:#e6db74">&#34;file </span><span style="color:#e6db74">{}</span><span style="color:#e6db74"> does not exist.&#34;</span><span style="color:#f92672">.</span>format(model_weight_path)   <span style="color:#75715e"># 判断该文件是否存在</span>
</span></span><span style="display:flex;"><span>    net<span style="color:#f92672">.</span>load_state_dict(torch<span style="color:#f92672">.</span>load(model_weight_path, map_location<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;cpu&#39;</span>))  <span style="color:#75715e"># 将权重文件加载到模型中</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 此处需要修改原模型的最后一层输入，1000 -&gt; 10，因为CIFAR10 只有10个类别</span>
</span></span><span style="display:flex;"><span>    in_channel <span style="color:#f92672">=</span> net<span style="color:#f92672">.</span>fc<span style="color:#f92672">.</span>in_features
</span></span><span style="display:flex;"><span>    net<span style="color:#f92672">.</span>fc <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(in_channel, <span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>    net<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># define loss function</span>
</span></span><span style="display:flex;"><span>    loss_function <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>CrossEntropyLoss()   <span style="color:#75715e"># 交叉熵</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># construct an optimizer</span>
</span></span><span style="display:flex;"><span>    params <span style="color:#f92672">=</span> [p <span style="color:#66d9ef">for</span> p <span style="color:#f92672">in</span> net<span style="color:#f92672">.</span>parameters() <span style="color:#66d9ef">if</span> p<span style="color:#f92672">.</span>requires_grad]
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># net.parameters() 返回模型net的所有参数（权重和偏置）</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># p.requires_grad 表示反向传播中，该参数的梯度是否会被计算并更新，如果为false，则不会被计算，因此在优化器中也不会更新</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># [p for p in net.parameters() if p.requires_grad] 这是一个列表推导式，遍历所有参数并筛选出requires_grad=True的参数</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 这样可以确保只优化那些需要更新的参数</span>
</span></span><span style="display:flex;"><span>    optimizer <span style="color:#f92672">=</span> optim<span style="color:#f92672">.</span>Adam(params, lr<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0001</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>    best_acc <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>
</span></span><span style="display:flex;"><span>    save_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;./ResNet34_retrain.pth&#39;</span>
</span></span><span style="display:flex;"><span>    train_steps <span style="color:#f92672">=</span> len(train_loader)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(epochs):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># train</span>
</span></span><span style="display:flex;"><span>        net<span style="color:#f92672">.</span>train()
</span></span><span style="display:flex;"><span>        running_loss <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>
</span></span><span style="display:flex;"><span>        train_bar <span style="color:#f92672">=</span> tqdm(train_loader, file<span style="color:#f92672">=</span>sys<span style="color:#f92672">.</span>stdout)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> step, data <span style="color:#f92672">in</span> enumerate(train_bar):
</span></span><span style="display:flex;"><span>            images, labels <span style="color:#f92672">=</span> data
</span></span><span style="display:flex;"><span>            optimizer<span style="color:#f92672">.</span>zero_grad()
</span></span><span style="display:flex;"><span>            logits <span style="color:#f92672">=</span> net(images<span style="color:#f92672">.</span>to(device))
</span></span><span style="display:flex;"><span>            loss <span style="color:#f92672">=</span> loss_function(logits, labels<span style="color:#f92672">.</span>to(device))
</span></span><span style="display:flex;"><span>            loss<span style="color:#f92672">.</span>backward()
</span></span><span style="display:flex;"><span>            optimizer<span style="color:#f92672">.</span>step()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># print statistics</span>
</span></span><span style="display:flex;"><span>            running_loss <span style="color:#f92672">+=</span> loss<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            train_bar<span style="color:#f92672">.</span>desc <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;train epoch[</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">/</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">] loss:</span><span style="color:#e6db74">{:.3f}</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format(epoch <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>, epochs, loss)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># validate</span>
</span></span><span style="display:flex;"><span>        net<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>        acc <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>  <span style="color:#75715e"># accumulate accurate number / epoch</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>            val_bar <span style="color:#f92672">=</span> tqdm(validate_loader, file<span style="color:#f92672">=</span>sys<span style="color:#f92672">.</span>stdout)
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> val_data <span style="color:#f92672">in</span> val_bar:
</span></span><span style="display:flex;"><span>                val_images, val_labels <span style="color:#f92672">=</span> val_data
</span></span><span style="display:flex;"><span>                outputs <span style="color:#f92672">=</span> net(val_images<span style="color:#f92672">.</span>to(device))
</span></span><span style="display:flex;"><span>                predict_y <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>max(outputs, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)[<span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>                acc <span style="color:#f92672">+=</span> torch<span style="color:#f92672">.</span>eq(predict_y, val_labels<span style="color:#f92672">.</span>to(device))<span style="color:#f92672">.</span>sum()<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>                val_bar<span style="color:#f92672">.</span>desc <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;valid epoch[</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">/</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">]&#34;</span><span style="color:#f92672">.</span>format(epoch <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>, epochs)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        val_accurate <span style="color:#f92672">=</span> acc <span style="color:#f92672">/</span> val_num
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">&#39;[epoch </span><span style="color:#e6db74">%d</span><span style="color:#e6db74">] train_loss: </span><span style="color:#e6db74">%.3f</span><span style="color:#e6db74">  val_accuracy: </span><span style="color:#e6db74">%.3f</span><span style="color:#e6db74">&#39;</span> <span style="color:#f92672">%</span>
</span></span><span style="display:flex;"><span>              (epoch <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>, running_loss <span style="color:#f92672">/</span> train_steps, val_accurate))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> val_accurate <span style="color:#f92672">&gt;</span> best_acc:
</span></span><span style="display:flex;"><span>            best_acc <span style="color:#f92672">=</span> val_accurate
</span></span><span style="display:flex;"><span>            torch<span style="color:#f92672">.</span>save(net<span style="color:#f92672">.</span>state_dict(), save_path) <span style="color:#75715e"># 保存模型</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;Finished Training&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#39;__main__&#39;</span>:
</span></span><span style="display:flex;"><span>    main()
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># load_weights.py</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> model <span style="color:#f92672">import</span> resnet34
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">main</span>():
</span></span><span style="display:flex;"><span>    device <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>device(<span style="color:#e6db74">&#34;cuda:0&#34;</span> <span style="color:#66d9ef">if</span> torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>is_available() <span style="color:#66d9ef">else</span> <span style="color:#e6db74">&#39;cpu&#39;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;using </span><span style="color:#e6db74">{</span>device<span style="color:#e6db74">}</span><span style="color:#e6db74"> device&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># load pretraion weights</span>
</span></span><span style="display:flex;"><span>    model_weights_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/Users/WH/Desktop/pytorch_classification/resnet34-333f7ec4.pth&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">assert</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>exists(model_weights_path), <span style="color:#e6db74">&#34;file </span><span style="color:#e6db74">{}</span><span style="color:#e6db74"> does not exist.&#34;</span><span style="color:#f92672">.</span>format(model_weights_path)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">#以下两种方法均涉及到对原模型结构的最后一层的修改</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># # 方法一</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># net = resnet34()</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># net.load_state_dict(torch.load(model_weights_path, map_location=device))</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># # 修改最后一层的全连接层结构</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># in_channel = net.fc.in_features</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># net.fc = nn.Linear(in_channel, 5)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 方法二</span>
</span></span><span style="display:flex;"><span>    net <span style="color:#f92672">=</span> resnet34(num_classes<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>    pre_weights <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>load(model_weights_path, map_location<span style="color:#f92672">=</span>device)
</span></span><span style="display:flex;"><span>    del_key <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> key,_ <span style="color:#f92672">in</span> pre_weights<span style="color:#f92672">.</span>items():
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> <span style="color:#e6db74">&#39;fc&#39;</span> <span style="color:#f92672">in</span> key:
</span></span><span style="display:flex;"><span>            del_key<span style="color:#f92672">.</span>append(key)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> key <span style="color:#f92672">in</span> del_key:
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">del</span> pre_weights[key]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    missing_keys, unexpected_keys <span style="color:#f92672">=</span> net<span style="color:#f92672">.</span>load_state_dict(pre_weights, strict<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;[missing_keys]:&#34;</span>, <span style="color:#f92672">*</span>missing_keys, sep<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;[unexpected_keys]:&#34;</span>, <span style="color:#f92672">*</span>unexpected_keys, sep<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    main()
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># predict.py</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> json
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> sys
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torchvision.datasets
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> PIL <span style="color:#f92672">import</span> Image
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torch <span style="color:#f92672">import</span> nn
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torch.utils.data <span style="color:#f92672">import</span> DataLoader
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torchvision <span style="color:#f92672">import</span> transforms
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> tqdm <span style="color:#f92672">import</span> tqdm
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> model <span style="color:#f92672">import</span> resnet34
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">main</span>():
</span></span><span style="display:flex;"><span>    device <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>device(<span style="color:#e6db74">&#34;cuda&#34;</span> <span style="color:#66d9ef">if</span> torch<span style="color:#f92672">.</span>cuda<span style="color:#f92672">.</span>is_available() <span style="color:#66d9ef">else</span> <span style="color:#e6db74">&#34;cpu&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    data_transform <span style="color:#f92672">=</span> transforms<span style="color:#f92672">.</span>Compose(
</span></span><span style="display:flex;"><span>        [transforms<span style="color:#f92672">.</span>Resize(<span style="color:#ae81ff">256</span>),
</span></span><span style="display:flex;"><span>         transforms<span style="color:#f92672">.</span>CenterCrop(<span style="color:#ae81ff">224</span>),
</span></span><span style="display:flex;"><span>         transforms<span style="color:#f92672">.</span>ToTensor(),
</span></span><span style="display:flex;"><span>         transforms<span style="color:#f92672">.</span>Normalize([<span style="color:#ae81ff">0.485</span>,<span style="color:#ae81ff">0.456</span>,<span style="color:#ae81ff">0.406</span>],[<span style="color:#ae81ff">0.229</span>,<span style="color:#ae81ff">0.224</span>,<span style="color:#ae81ff">0.225</span>])]
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    data_root <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;./data&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">assert</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>exists(data_root) , <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;file: </span><span style="color:#e6db74">{</span>data_root<span style="color:#e6db74">}</span><span style="color:#e6db74"> does not exist&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    dataset <span style="color:#f92672">=</span> torchvision<span style="color:#f92672">.</span>datasets<span style="color:#f92672">.</span>CIFAR10(
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;./data&#34;</span>,
</span></span><span style="display:flex;"><span>        train<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>        transform<span style="color:#f92672">=</span>data_transform,
</span></span><span style="display:flex;"><span>        download<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    num <span style="color:#f92672">=</span> len(dataset)
</span></span><span style="display:flex;"><span>    dataloader <span style="color:#f92672">=</span> DataLoader(dataset,
</span></span><span style="display:flex;"><span>                            batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>,
</span></span><span style="display:flex;"><span>                            shuffle<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>                            num_workers<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> resnet34()
</span></span><span style="display:flex;"><span>    in_channel <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>fc<span style="color:#f92672">.</span>in_features
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>fc <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(in_channel, <span style="color:#ae81ff">10</span>)
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>load_state_dict(torch<span style="color:#f92672">.</span>load(<span style="color:#e6db74">&#34;ResNet34_retrain.pth&#34;</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    acc <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>
</span></span><span style="display:flex;"><span>    train_bar <span style="color:#f92672">=</span> tqdm(dataloader, file<span style="color:#f92672">=</span>sys<span style="color:#f92672">.</span>stdout)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> imgs , target <span style="color:#f92672">in</span> train_bar:
</span></span><span style="display:flex;"><span>            imgs <span style="color:#f92672">=</span> imgs<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>            target <span style="color:#f92672">=</span> target<span style="color:#f92672">.</span>to(device)
</span></span><span style="display:flex;"><span>            model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            output <span style="color:#f92672">=</span> model(imgs)
</span></span><span style="display:flex;"><span>            pre_label <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>argmax(output,dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>            acc <span style="color:#f92672">+=</span> torch<span style="color:#f92672">.</span>eq(pre_label, target<span style="color:#f92672">.</span>to(device))<span style="color:#f92672">.</span>sum()<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    acc <span style="color:#f92672">/=</span> num
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;测试准确率为</span><span style="color:#e6db74">{</span>acc<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    main()
</span></span></code></pre></div>
</section>


    <footer class="article-footer">
    

    </footer>


    
</article>

    

    

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
        2024 Carp&#39;s blog
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.26.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
